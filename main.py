#!/usr/bin/env python3
import argparse
import datetime as dt
import os
import sys
from typing import Any, Dict, List

import requests
from dotenv import load_dotenv
from langchain.output_parsers import PydanticOutputParser
from langchain.prompts import ChatPromptTemplate
from langchain_openai import ChatOpenAI
from pydantic import BaseModel, Field
from tenacity import retry, stop_after_attempt, wait_exponential

GITHUB_API = "https://api.github.com/search/repositories"


class RepoDigest(BaseModel):
    summary: str = Field(description="æŠ€è¡“ã®è¦ç‚¹ã‚’2-3æ–‡ã§")
    why_care: str = Field(description="ä»Šä½¿ã†ä¾¡å€¤ã‚’ä¸€è¨€ã§")
    use_cases: list[str] = Field(default_factory=list, description="å…·ä½“ç”¨é€” æœ€å¤§3")
    setup: list[str] = Field(default_factory=list, description="æœ€çŸ­æ‰‹é † 2-4è¡Œ")
    difficulty: int = Field(ge=1, le=5, description="1=æ˜“ 5=é‡")


def build_chain():
    parser = PydanticOutputParser(pydantic_object=RepoDigest)
    prompt = ChatPromptTemplate.from_messages(
        [
            ("system", "ã‚ãªãŸã¯å„ªç§€ãªMLã‚¨ãƒ³ã‚¸ãƒ‹ã‚¢ã®ç·¨é›†è€…ã€‚å‡ºåŠ›ã¯å¿…ãšJSONã®ã¿ã€‚"),
            (
                "user",
                """æ¬¡ã®GitHubãƒªãƒã‚’ã€å®Ÿå‹™ã‚¨ãƒ³ã‚¸ãƒ‹ã‚¢ãŒâ€œä»Šæ—¥è§¦ã‚‹ã‹æ±ºã‚ã‚‹â€ãŸã‚ã®æœ€å°æƒ…å ±ã«è¦ç´„ã€‚
å…¥åŠ›:
- name: {name}
- url: {url}
- description: {desc}
- meta:
  Language: {lang}
  Stars: {stars}

è¦ä»¶:
- summary: 2-3æ–‡
- why_care: ä¸€è¨€
- use_cases: æœ€å¤§3ï¼ˆåè©å¥ï¼‰
- setup: 2-4è¡Œï¼ˆç®‡æ¡æ›¸ã/æœ€çŸ­æ‰‹é †ï¼‰
- difficulty: 1-5ï¼ˆ1=è¶…ç°¡å˜ï¼‰

{format_instructions}""",
            ),
        ]
    ).partial(format_instructions=parser.get_format_instructions())

    llm = ChatOpenAI(
        model=os.getenv("OPENAI_MODEL"), openai_api_key=os.getenv("OPENAI_API_KEY")
    )
    return prompt | llm | parser


def summarize_with_langchain(repo: Dict[str, Any], chain) -> RepoDigest:
    return chain.invoke(
        {
            "name": repo["full_name"],
            "url": repo["html_url"],
            "desc": (repo.get("description") or "").strip(),
            "lang": repo.get("language") or "-",
            "stars": repo.get("stargazers_count", 0),
        }
    )


def slack_block_with_digest(i: int, it: Dict[str, Any], d: RepoDigest) -> str:
    uc = " ãƒ»".join(d.use_cases[:3]) if d.use_cases else "â€”"
    setup = "\n".join([f"   - {s}" for s in d.setup[:4]]) if d.setup else ""
    return (
        f"{i}. {it['full_name']} â˜…{it['stargazers_count']}\n"
        f"   {it['html_url']}\n"
        f"   {d.summary}\n"
        f"   ğŸ§  {d.why_care} / é›£æ˜“åº¦â˜…{d.difficulty}\n"
        f"   ä½¿ã„ã©ã“ã‚: {uc}\n"
        f"{setup}\n"
    )


def build_query(language: str, days: int, use_created: bool) -> str:
    """Search APIã§â€œæ“¬ä¼¼ãƒˆãƒ¬ãƒ³ãƒ‰â€ã‚’ä½œã‚‹ãŸã‚ã®ã‚¯ã‚¨ãƒªã‚’ç”Ÿæˆ"""
    since = (dt.date.today() - dt.timedelta(days=days)).isoformat()
    date_field = "created" if use_created else "pushed"
    # ä¾‹: language:Python + created:>=2025-09-02
    return f"language:{language} {date_field}:>={since}"


def format_markdown(items: List[Dict[str, Any]], top: int, title: str) -> str:
    md = [
        f"# {title}",
        "",
        f"å®Ÿè¡Œæ—¥æ™‚: {dt.datetime.now().isoformat(timespec='seconds')}",
    ]
    md.append("")
    for i, it in enumerate(items[:top], 1):
        name = it["full_name"]
        url = it["html_url"]
        stars = it["stargazers_count"]
        desc = (it.get("description") or "").strip().replace("\n", " ")
        lang = it.get("language") or "-"
        created = it["created_at"]
        pushed = it["pushed_at"]
        md.extend(
            [
                f"## {i}. [{name}]({url})  â˜…{stars}",
                f"- è¨€èª: `{lang}`",
                f"- created: `{created}` / pushed: `{pushed}`",
                f"- æ¦‚è¦: {desc or 'â€”'}",
                "",
            ]
        )
    return "\n".join(md)


def post_slack(webhook: str, text: str) -> None:
    payload = {"text": text}
    r = requests.post(webhook, json=payload, timeout=20)
    r.raise_for_status()


@retry(wait=wait_exponential(min=2, max=20), stop=stop_after_attempt(3))
def search_repos(token: str, query: str, per_page: int) -> Dict[str, Any]:
    headers = {
        "Authorization": f"Bearer {token}",
        "Accept": "application/vnd.github+json",
        "User-Agent": "trend-daily-script",
    }
    params = {"q": query, "sort": "stars", "order": "desc", "per_page": per_page}
    r = requests.get(GITHUB_API, headers=headers, params=params, timeout=30)
    # Rate limit æ™‚ã¯ãƒªãƒˆãƒ©ã‚¤
    if r.status_code == 403 and "rate limit" in r.text.lower():
        raise RuntimeError("GitHub API rate limited")
    r.raise_for_status()
    return r.json()


def main():
    load_dotenv()

    parser = argparse.ArgumentParser(
        description="Fetch pseudo-trending repos via GitHub Search API."
    )
    parser.add_argument(
        "--language", default="Python", help="è¨€èªãƒ•ã‚£ãƒ«ã‚¿ï¼ˆä¾‹: Python, TypeScriptï¼‰"
    )
    parser.add_argument(
        "--days", type=int, default=3, help="ä½•æ—¥å‰ã¾ã§ã‚’å¯¾è±¡ã«ã™ã‚‹ã‹ï¼ˆä½œæˆ/æ›´æ–°æ—¥ï¼‰"
    )
    parser.add_argument("--top", type=int, default=5, help="ä¸Šä½ä½•ä»¶ã‚’è¡¨ç¤ºã™ã‚‹ã‹")
    parser.add_argument(
        "--per-page", type=int, default=30, help="APIã‹ã‚‰å–å¾—ã™ã‚‹æœ€å¤§ä»¶æ•°ï¼ˆä¸Šä½æŠ½å‡ºç”¨ï¼‰"
    )
    parser.add_argument(
        "--use-created",
        action="store_true",
        help="pushed ã§ã¯ãªã created ã‚’åŸºæº–ã«ã™ã‚‹",
    )
    parser.add_argument(
        "--markdown-out", default="", help="Markdownã‚’æ›¸ãå‡ºã™ãƒ‘ã‚¹ï¼ˆä¾‹: out.mdï¼‰"
    )
    parser.add_argument(
        "--slack",
        action="store_true",
        help="Slackã«æŠ•ç¨¿ã™ã‚‹ï¼ˆSLACK_WEBHOOK_URL ãŒå¿…è¦ï¼‰",
    )
    parser.add_argument(
        "--title", default="ä»Šæ—¥ã®GitHubãƒˆãƒ¬ãƒ³ãƒ‰", help="Markdown/Slackè¦‹å‡ºã—"
    )
    args = parser.parse_args()

    token = os.getenv("TREND_READ_GITHUB_TOKEN")
    if not token:
        print(
            "ERROR: TREND_READ_GITHUB_TOKEN ãŒæœªè¨­å®šã§ã™ã€‚ .env ã«è¨­å®šã—ã¦ãã ã•ã„ã€‚",
            file=sys.stderr,
        )
        sys.exit(1)

    query = build_query(args.language, args.days, args.use_created)
    data = search_repos(token, query, args.per_page)
    items = data.get("items", [])

    # å‡ºåŠ›ï¼ˆã‚³ãƒ³ã‚½ãƒ¼ãƒ«ï¼‰
    for i, it in enumerate(items[: args.top], 1):
        print(f"{i}. {it['full_name']}  â˜…{it['stargazers_count']}  {it['html_url']}")

    # Markdown
    if args.markdown_out:
        md = format_markdown(items, args.top, args.title)
        with open(args.markdown_out, "w", encoding="utf-8") as f:
            f.write(md)
        print(f"\n[INFO] Markdown ã‚’æ›¸ãå‡ºã—ã¾ã—ãŸ -> {args.markdown_out}")

    # Slack
    if args.slack:
        webhook = os.getenv("SLACK_WEBHOOK_URL")
        if not webhook:
            print(
                "WARN: SLACK_WEBHOOK_URL ãŒæœªè¨­å®šã®ãŸã‚ Slack æŠ•ç¨¿ã‚’ã‚¹ã‚­ãƒƒãƒ—ã—ã¾ã—ãŸã€‚",
                file=sys.stderr,
            )
        else:
            chain = build_chain()
            text_lines = [args.title, ""]

            for i, it in enumerate(items[: args.top], 1):
                d = summarize_with_langchain(it, chain)
                text_lines.append(slack_block_with_digest(i, it, d))

                text_lines.append(f"   {(it.get('description') or '').strip()}")

            post_slack(webhook, "\n".join(text_lines))
            print("[INFO] Slack ã«æŠ•ç¨¿ã—ã¾ã—ãŸã€‚")


if __name__ == "__main__":
    main()
